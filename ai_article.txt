AI Won’t Replace Humans — But Humans With AI Will Replace Humans Without AI

Just as the internet has drastically lowered the cost of information transmission, AI will lower the cost of cognition. That’s according to Harvard Business School professor Karim Lakhani, who has been studying AI and machine learning in the workplace for years. As the public comes to expect companies that deliver seamless, AI-enhanced experiences and transactions, leaders need to embrace the technology, learn to harness its potential, and develop use cases for their businesses. “The places where you can apply it?” he says. “Well, where do you apply thinking?”

For this episode of our video series “The New World of Work”, HBR editor in chief Adi Ignatius sat down with Lakhani, author of Competing in the Age of AI: Strategy and Leadership When Algorithms and Networks Run the World, to discuss:

How executives and regular employees can (and must) develop a digital mindset
Change management as a critical skill that must be in the DNA of any successful organization
The shapes AI may take in the near and far future
“The New World of Work” explores how top-tier executives see the future and how their companies are trying to set themselves up for success. Each week, Ignatius talks to a top leader on LinkedIn Live — previous interviews included Microsoft CEO Satya Nadella and former PepsiCo CEO Indra Nooyi. He also shares an inside look at these conversations —and solicits questions for future discussions — in a newsletter just for HBR subscribers. If you’re a subscriber, you can sign up here.

ADI IGNATIUS:

Karim, welcome to the show.

Karim Lakhani:

So glad to be here with you today, Adi.

ADI IGNATIUS:

You co-wrote a piece for us a few years ago, and it’s reflected in your book, where you say machine learning has basically changed the very rules of business. That’s a big statement. What do you mean by that?

Karim Lakhani:

The book really was a partnership between Marco Iansiti and Amy Bernstein, one of the editors at HBR. And what Marco and I noticed in about a decade’s worth of research and spending time with companies, both writing cases as advisors, as consultants, and so forth, was that the nature of the corporation (which really was established as the modern American corporation, which became the blueprint for the modern international corporation, established in the 1920s and 30s) was changing foundationally because of technologies like AI, like machine learning.

What we observed was that the entire business architecture in many of these AI-first companies at that time, in terms of business model, how you create value, how you capture value, and your operating model, how you deliver value, how you achieve scope, the number of customers you serve, the number of products you have, scale, the number of customers you serve, and learning these fundamental parts of a business architecture, were being rewired because of machine learning, AI, and digital technologies.

If you just reflect for a bit on your experience using Google, for example, much of your Google experience is fully automated, from the ads you see to the search you do to, if you’re using Gmail, how you interact with them. It’s not people that do those activities, it’s the algorithms that make that happen. Similarly with all the large e-commerce platforms like an Amazon or Alibaba or Netflix. But these companies work in a fundamentally different way than a company like General Electric, where I grew up right out of college in my first job.

These companies, the machines and the algorithms are at the center. The work is automated. The humans are actually designing the algorithms and testing them and checking them, making sure they’re working within bounds, but the actual transactions and activities are being mediated through the machines.

ADI IGNATIUS:

What’s your advice to people who are listening to this who are like, “Yeah, I get it. I get that there’s value here. I’m not quite sure if my company is right for this, or I’m not quite sure what the next steps are”?

Karim Lakhani:

First, I would say that most companies will not have a choice but to adopt AI and adopt digital at the core functions. In many ways, your personal lives are mediated through your transactions, through your smartphone, through these devices, and how you interact with consumer technology products: you are already living in an AI age.

I learned from some conversations I had with folks in India, they said, “We have some folks who get mad when your Uber car or your Ola car doesn’t show up in three minutes.” You want this magical taxi experience. You go on your app, you press the thing, boom, it shows up. And if it’s going to be five or seven minutes, you kind of get mad. I’m reflecting on when I first moved to Boston in 1997, and it would take me a week to book a taxi in Boston. Now, we get mad.

Similarly, if there’s a transaction dispute on Amazon or Uber, it’s automatically solved, done. But the same people, the same executives, in their own companies are completely satisfied if a customer service interaction can take two weeks, if onboarding a new vendor takes six months. We’re living in this disconnected world where most people, most consumers, are living in an AI-first world in their experiences with many of these platforms. And then, they encounter our companies and our organizations, and they’re like, “What is this?”

My sense is that this is inevitable. This transition is really inevitable. And for the folks that are behind, the good news is that the cost to make the transition keeps getting lower and lower. The playbook for this is now well-known. And finally, the real challenge is not a technological challenge. I would say that’s like a 30% challenge. The real challenge is 70%, which is an organizational challenge. My great colleague Tsedal Neeley talks about the digital mindset. Every executive, every worker needs to have a digital mindset, which means understanding how these technologies work, but also understanding the deployment of them and then the change processes you need to do in terms of your organization to make use of them.

ADI IGNATIUS:

We’re a relatively small publisher compared to some of the giants out there. But when people come to our site, and they’re searching for articles by Karim Lakhani, they’re used to a Google sort of search experience.

Karim Lakhani:

Exactly.

ADI IGNATIUS:

When they want to buy a product from us, they’re used to an Amazon, and anything short of that, it’s like your Uber example. There’s a frustration and expectation. So we have to find ways to lift our game without the resources, whether it’s through partnerships or other things, because it’s table stakes. People just expect the best experience in every experience they have.

Karim Lakhani:

One hundred percent, and if I look at my teenage daughter, she has no patience for old line companies. She just gets mad and is like, “What is this?”

ADI IGNATIUS:

The next big wave is generative AI. But that won’t be the last wave, and quantum will hit us at some point, and things we can’t even anticipate will hit us. How do you prepare for that? How do you create a culture or mindset or organization that knows there will be unexpected waves of technology, we’ll have to figure out if they’re relevant to us or not, and if they are, we need to adapt quickly? Is there a general way to think about that?

Karim Lakhani:

I think there are two imperatives for most executives, for most managers, for most leaders. One is a learning imperative. This is, again, Tsedal [Neeley]’s work on digital mindset, and my work. There’s lots of learning you need to do, and the learning has to be continuous. The idea is not that we want you to become AI engineers or data scientists or get a Ph.D., but as executives, this is now table stakes.

The way I think about this at the MBA program for us, is that people come to the Harvard MBA program and we have a first year required curriculum. There are 10 courses and one of them is accounting. I can tell you, accounting is a very important profession, but most MBAs that join HBS don’t want to be accountants. But they need to learn accounting because that’s the language of business. That’s the way in which you think about how value is kept track of, how expenses are tracked, and so on. Super important.

You don’t take the accounting course to become accountant, but you need to understand accounting so you can be a good business person. Same thing now with digital technologies and machine learning. You need to understand the machine learning stuff and the AI stuff, not because you’re going to become an AI engineer or an AI scientist, but because that is now going to be a critical table stakes for you to understand how business works.

There’s a learning imperative and I don’t think we can take away the learning imperative anymore. I’m self-centered about this. I’m self-interested. I’m in the learning profession. So, I want to caveat that. But I want to just insist that the learning journey does not stop and you have to invest in your own personal learning, and I think companies need to invest in the learning for their own employees as well. It’s a two-phased conversation. Companies have to embrace this and so do individuals.

But the second bit is equally important, which is completely underrated: change and change management become skills for managers and for leaders and for executives. How you change, how you continuously change, how you build a DNA for changing becomes very important.

I was in Asia a month ago and had a chance to spend some time with Mickey Mikitani at Rakuten. He has thought about change as a core competency for all workers and all employees. Right now, most change programs are viewed with skepticism, flavor of the month, blah, blah, blah. People resist.

The best companies will be the ones that can understand how change becomes a skill. If you think about change as a skill, what does that mean? Skills require acquisition of the skills. You’ve got to invest in learning. What does it mean to change? It requires practice. You’ve got to keep changing as well. And it requires adjustment. Those elements I think will become a key part of the ways in which leaders need to adapt to this world.

ADI IGNATIUS:

It could be generational but it should not be generational. I always think that when you come of age, when you join the workforce, there’s a certain suite of technology that you grew up with and you’re comfortable with and you are part of figuring out how to use it. Subsequently, a lot of us hit a point where a new one seems stupid. For my father who’s still alive at 102, that was email. Right?

Karim Lakhani:

Yes.

ADI IGNATIUS:

So you’ve got to keep trying. You’ve got to keep experimenting. You have to keep current.

Karim Lakhani:

Around Covid I had this experience with my mother who lived in Toronto, and my in-laws were also living in Toronto. When things eased up a bit in November of 2020, when Thanksgiving was on, we were able to fly them back to have a reunion with them. When things eased up a bit with the vaccines and so on and so forth, we were able to bring them over. And if you recall, traveling, even just crossing the border from Canada to the US, was very difficult because you had QR codes and apps galore. Canada needed all this stuff to exit, US needed it to enter.

And I looked at how, sadly, helpless my in-laws and my parents were with these technologies. They were just lost and my wife and my daughter and I had to spend a ton of time with them, holding their hands, to go through these things. Of course the UX was terrible, but we figured out how to do it ourselves. But they were stuck. They couldn’t adjust.

As I reflected on that experience, I said, “Oh, this is what’s happening to most executives. This is what’s happening to most companies.” They’re like the senior citizens, the elderly, who have resisted the technology, have not really embraced it, and now have no choice but to deal with it and are frozen and need a ton of help. That’s the thing we have to get over as we think about this.

ADI IGNATIUS:

OK, generative AI. I like to say that there were three waves. The first was that we played with this technology when it came out. Then we tried to break it by asking, “ChatGPT. Are you in love with me?”

Karim Lakhani:

Yes.

ADI IGNATIUS:

And now we’re trying to figure out how to use it. Where are you in the hype cycle?

Karim Lakhani:

I’m like, “Holy crap! This is transformational.” The way I think about this is that it’s actually worth it to pause and look at history. Since I studied technology and business, something transformational happened 30 years ago approximately as well, which was the [web] browser got invented. If you think about the browser, there were 30 years of the internet, then the browser gets invented, and people were like, “Oh my goodness. Look at this.”

I remember I could still see as clear as day when I first clicked on the browser, and I was working in General Electric, I was at a conference for radiology, and one of my clients, a radiologist at St. Paul’s Hospital in Vancouver, showed me the browser, and the thing he showed me was the Oxford Coffee Pot. I’m like, “Huh. Interesting.” All of a sudden, the Oxford Coffee Pot has global distribution. Anybody that has a web browser and internet connection can use it.

There’s 30 years of internet in the basement, in the bowels of companies. We didn’t understand it. We saw it was coming, it was coming. It was Usenet, there was Gopher, there was Telnet, there was FTP, all these kinds of things. Then the browser showed what the world would look like. And the initial applications were cute applications and people were like, “Ah. This is nothing. This is whatever.” But fundamentally, from an economics point of view, what the browser did is that it lowered the cost of information transmission dramatically.

Then in the last 30 years, we’ve been living through the build out of the internet, and waves and waves of the internet changing more and more industries, over and over again. We’ve all living through that.

We are broadcasting live to, I don’t know, thousands of people, and then more people will be looking at this broadcast, at relatively zero marginal cost to us. This seems unbelievable compared to 1993 where you needed a massive TV studio, massive broadcast studio, satellite dishes to be able to do what we’re doing right now. The cost of information transmission went to zero, and then new companies formed, Google, Amazon, Facebook, you name it, e-commerce got invented. That is the world we are coming out of.

The same thing’s happened with generative AI. There’s been 20 years of AI being deployed at scale inside of many tech companies. That was in the basement. Netflix movie recommendations, your Google search results, your Amazon recommendations, your Spotify music results, your car access, your Waze access, your directions. All that was being empowered by AI tools. Even your spam killers. Remember how bad spam used to be for a while, and then overnight it went away? Because people deployed machine learning systems.

How do we think about generative AI? My view is generative AI is a drop in the cost of cognition and how we think. If the internet was the cost of information dropping to zero, my sense is that the cost of cognition, how we think, who we think with, is dropping to zero, or lowering significantly.

That has significant ramifications. I had to do a major pivot even in my research on what to do with this. I was doing a lot of stuff around AI adoption. A lot of research, a lot of nerdy research that only three people will read, but my whole institute and my labs have gone big time into figuring out what this means for knowledge workers, for managers with generative AI.

ADI IGNATIUS:

Let’s talk about that. There are products available that are using this, that rolled out pretty quickly. Is there a way to think about this generically? For a generic company, if there is such a thing, how should they think about using generative AI?

Karim Lakhani:

First of all, we’re in the super early stages of this hype, of this cycle. If you think about it the first web browser was Mosaic, and then Netscape and Explorer and Mozilla came along. Then all the applications on top. We are at the early stages. The rate of innovation and the rate of improvement is increasing rapidly, and it keeps increasing. The rate of application development is also increasing rapidly.

The places where you can apply it is—well, where do you apply thinking? Where else could you apply this, right?

With all the caveats about hallucination and bias and so forth, if you step back and say, what should leaders do? What should managers do, what should executives do around this thing? One is to start thinking about and start practice in their own sandboxes what the use cases may be. We’re seeing tremendous use cases, for example, just in content generation. Our work, as knowledge producers, that’s changing rapidly. I use ChatGPT as an amazing research associate, thought partner, copy editor, idea generator.

I was in Asia, my wife was with me on my trip, and I wanted to actually have some time for a break. I went to ChatGPT and I said, “This is me, this is my wife. Here’s the kind of vacations we like. Can you please give us ideas of a place that would be about three hours from Singapore that we go to, and I prefer a beach, etc.” Boom. In microseconds, I got many recommendations. And then through a conversational setup, I found the place that we wanted to go to, and it was a hidden place in the South China Sea off Indonesia. And it was incredible. It was incredible. And that I would not have discovered even with a travel agent. So, just even in that activity, just imagine what we can now start to do with this.

The thing managers and leaders need to do is, step one, start using it. The bans on ChatGPT and these things are misguided in many companies. It’s already on my phone. There are a hundred million users, it’s already there. I think executives and IT departments and legal departments are fooling themselves if they don’t think their workers are already using these tools.

Instead of pushing against it and saying, “No,” you need to embrace it and run bootcamps, run use case analysis, figure out where it’s useful in your use cases, and figure out where it’s actually going to be very helpful.

What I say to managers, leaders, and workers is: AI is not going to replace humans, but humans with AI are going to replace humans without AI. This is definitely the case for generative AI. The first step is to begin, start experimentation, create the sandboxes, run internal bootcamps, and don’t just run bootcamps for technology workers, run bootcamps for everybody. Give them access to tools, figure out what use cases they develop, and then use that as a basis to rank and stack them and put them into play.

ADI IGNATIUS:

I agree with that. We have to think about that as a publisher. There’s some publishers who say we will not take articles or papers where generative AI has been involved. That doesn’t make sense. It’s like saying don’t use Google. It’s a tool. What we’re saying though is that the responsibility, more than ever, is on the person with the byline on this piece. That was true, you didn’t want to just use Google search results or just use Wikipedia results. You need to verify and do a little bit more than that, now more than ever.

Karim Lakhani:

Absolutely. As scholars, we publish these nerdy papers that very few people read, and we’re in the same crisis. If I use a research assistant to come up with ideas, do I have to acknowledge them? Is the assistant a co-author? If I use a copy editor, I typically don’t acknowledge a copy editor for my article, but they’re super helpful. Attribution becomes interesting. There’s so many important questions at play just as writers and producers.

The best place to learn, Adi, is YouTube. YouTube has, oh my God, so many tutorials in so many domains.

ADI IGNATIUS:

I think there’s a trap that sometimes people feel like if they don’t jump on the wave immediately, somehow it’s too late.

Karim Lakhani:

No, no. Gosh, no.

ADI IGNATIUS:

I think it’s really early. If you’re right that this is truly transformative, it’s early. If you feel like, “Wow, everybody’s moving faster than I am,” then catch up. Whether it’s YouTube or just doing some reading and figuring out how it applies. Let me go to some questions from the audience. This is from Veena from somewhere in the US. AI is somebody’s code. It comes with biases and assumptions built in. How can the industry ensure there isn’t a monopoly on how we think and how we’re biased, and the assumptions that we make?

Karim Lakhani:

I as an individual, I’m part of Mozilla. We made the Firefox browser owned by an open source foundation, Mozilla Foundation. If you haven’t used Firefox in a while, go back and use it again. We’ve just set up mozilla.ai, and the idea is that we want to create open source large language models and create the tooling that enables many people around the world to have large language models suited for them. Our view is that we can build tools to detect bias and fix bias, and to fix all the craziness that these larger language models can do. So, I’m actively working in trying to create and support organizations that do that.

The first thing we need to do is step back and say the world is biased. We had bias before there was AI. AI is just amplifying it and making it apparent. The world is biased. You look at the unbelievably bad treatment African Americans receive in our healthcare system and in our financial system, and so on in the US. Or if you go to some other country, there’s always been discrimination without AI. AI is helping to amplify it.

The ethical responsibility for us as leaders has to be that we have to understand what is biased today in our systems. How representative is your data? How representative is your training? How representative is your labeling? Those are essential, essential questions that need to be part of the executive conversation. That’s where the learning mandate doesn’t stop, because you have to understand how these machine learning systems are built for you, to understand what the biases are, and how you might get sued or be put in jail, for God’s sakes, if you don’t follow through on these things.

This is super important, but I want us to also be aware that we need to think counter factually, there’s always this bias in the world. And now let’s imagine a world with AI, and is it going to take the bias world and amplify it or can we correct for it? Can we recognize it for it? That’s going to be very important.

ADI IGNATIUS:

Yeah, this depends on if you’re a techno-optimist or a techno-pessimist.

Karim Lakhani:

Yes, I tend to be on the optimist side.

ADI IGNATIUS:

Here’s a different question. This is from Janelle in Washington, DC. We were talking about dealing with waves of technology and changing and adapting. We’ve been talking about how your employees can learn and adapt, but how do you help the customer learn?

Karim Lakhani:

This is a great question. I think customers tend to be ahead. I was in sales and marketing for four years at General Electric, and my customers knew what I had and what I didn’t have and what we were good at and what we were not good at, they wouldn’t talk to me about things that we were not good at or we weren’t exploring. I never got that message until much later.

I discovered, “Oh, you’re interested in this? Oh, we’ve got some nascent product, whatever,” but I said, “No,” because we knew GE was not going to be good here, so we didn’t talk to you. I think you’d be surprised, especially today’s customers, because again, as I mentioned, all of them are living in a digital age with our smartphones and our capabilities. You’d be surprised at how fast they adapt, and in many situations with other companies that are already further down the pike than with you.

We get the wrong signals from our sales teams, from our marketing teams, even from our focus groups, because we actually don’t observe customers in situ and see what’s going on. You think about the median user of Facebook, I think they’re like 50 or something right now. Adoption is no longer as big a deal.

ADI IGNATIUS:

My generation ruined MySpace and now we’re going to ruin Facebook.

Karim Lakhani:

I know. Look at that. Now, we’re aging out of Facebook too.

ADI IGNATIUS:

We’ll get TikTok next. The last question: generative AI has evolved until it almost feels sentient. Is this machine developing emotional intelligence, or are we on the path to that? Is that a pure illusion, or are we heading towards something that will at least feel like an intelligence and an emotional intelligence in these machines?

Karim Lakhani:

I always say to be kind to your robots, OK? Always say please and thank you when you’re using Chat GPT or Bard. I do that as a principle. I tell everybody, be kind to your robots because if the sentience moment shows up, all the data will be there, all the history of our records with these systems will be there. And you don’t want them to get pissed off because, “Hey, Karim was a bad actor for us.” I’m an ardent atheist, but I still say inshallah.

ADI IGNATIUS:

Just in case.

Karim Lakhani:

Who knows? Just in case, hedge your bets. Like I say inshallah, we should always say please and thank you to your robots. That’s the first thing. The second thing is that right now, the human-like responses are a statistical illusion. They absolutely are. They’ve just been well-trained by humans to respond to humans, and they’ve used all our texts and all our videos to be human-like in many ways. But in the end, it’s a statistical or computational illusion.

But I should tell you, I got a little bit of a wake-up call on this. I felt like this stuff, like the strong AI stuff that has been talked about, all this stuff is what we call weak AI. The strong AI stuff is many decades away. But in conversations with leaders at Harvard, at the Kempner Institute, which is the new Institute for National Intelligence and Artificial Intelligence, we talk about the marrying of biology with AI and AI with biology. Two amazing scholars, I asked (this is pre-Chat GPT), “What do you guys think? How far away is this strong AI world?”

They said 20 years. And I was like, “Whoa, I’m not ready for that.” But if the world experts, people that know better than I do on this, are saying 20 years, it might even be faster. The thing that’s interesting to me, Adi, is we may not even know when it has sentience, right? It’s like we assume human-like forms on intelligence. But if you read a lot of science fiction like I do, maybe alien life is going to be carbon based, but maybe not. Maybe they’ll have a different metabolic system, maybe different neural systems, and you need to be ready for that. We may not even know it, that’s the thing.

ADI IGNATIUS:

This is fabulous. We’re going to have to get you back on the show because there’s a lot more to talk about and we didn’t even get into the congressional hearings on aliens.

Karim Lakhani:

Oh gosh, yes.

ADI IGNATIUS:

This is just a half step away from that. So, this has been Karim Lakhani, Harvard Business School professor. Karim, thank you very much for being on the show.

Karim Lakhani:

Great to be here with you, Adi. Thank you.

CQ